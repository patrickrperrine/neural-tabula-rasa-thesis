{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e0a916e",
      "metadata": {
        "id": "1e0a916e"
      },
      "source": [
        "# Neuroidal Model Simulation v1.3\n",
        "#### Patrick Perrine\n",
        "\n",
        "Code for:\n",
        "\n",
        "    Perrine, P. R. (2023). Neural Tabula Rasa: Foundations for Realistic Memories and Learning. Master's thesis. California Polytechnic State University, San Luis Obispo.\n",
        "\n",
        "The algorithms implemented here are adapted from or inspired by:\n",
        "\n",
        "    Valiant, L. G. (2005). Memorization and Association on a Realistic Neural Model. Neural Computation, 17, 527–555. https://doi.org/10.1162/0899766053019890\n",
        "\n",
        "Many thanks to Mugizi Rwebangira and Chandradeep Chowdhury for their constant support."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MW6UFTD5Yirb",
      "metadata": {
        "id": "MW6UFTD5Yirb"
      },
      "source": [
        "## Introduction\n",
        "We offer the following simulation as an accurate, centralized interpretation of the Neuroidal model, as specifically described by Valiant (2005). We place an emphasis on simulating the model to study the behavior of the one-step, shared memory representation for use in unsupervised memorization via the JOIN algorithm. We offer a general implementation framework that should easily extend to the other variants of the model. We offer a new algorithmic primitive *quick JOIN* (simplified as *QJOIN*) which allows for a significantly faster instance of JOIN to be executed for a centralized representation of the Neuroidal model.\n",
        "\n",
        "We omit an implementation of the LINK procedure, as we do not measure this model based on its ability to *associate* items of information. We are primarily concerned with how much information can be stored using JOIN before an intolerable amount of interference occurs between new and pre-existing memories. Another critical difference is that our algorithms do not function in a distributed manner, leading to some complexity issues that we mitigate with optimization procedures.\n",
        "\n",
        "The use of the \"mode\" structure for storing neuron/synapse parameters are an effort to remain aesthetically similar the original formulations in Valiant (2005), and the earlier work *Circuits of the Mind*. Given our centralized strategy here, there is evidence to suggest that this mode format may be later disregarded.\n",
        "\n",
        "We choose the Python library *graph-tool* to serve as the basis for storing and performing operations on our random graph model. We opt for this particular library due to its reported performance, code readability, and implementations for visualizing very large, dense graphs (which we leave for future work). We also synonymously refer to nodes as 'neurons', edges as 'synapses', and the graph as 'the model.'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6ca44a",
      "metadata": {
        "id": "3f6ca44a"
      },
      "source": [
        "### Install the *graph-tool* library (https://graph-tool.skewed.de/)\n",
        "The following two code blocks are subject to change based on the library's current hosting location, so referring to the current information from its website may be required.\n",
        "\n",
        "If one needs to run this code without Jupyter: Ignore the following two blocks and please refer to the library's current documentation for proper installation instructions for the desired setup. Also, be sure to remove the \"%%capture\" markers in any subsequent code blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bKylUrLvqy18",
      "metadata": {
        "id": "bKylUrLvqy18"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!echo \"deb http://downloads.skewed.de/apt jammy main\" >> /etc/apt/sources.list\n",
        "!apt-key adv --keyserver keyserver.ubuntu.com --recv-key 612DEFB798507F25\n",
        "!apt-get update\n",
        "!apt-get install python3-graph-tool python3-matplotlib python3-cairo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "LUmecdYbVIQw",
      "metadata": {
        "id": "LUmecdYbVIQw"
      },
      "outputs": [],
      "source": [
        "# Run this block if you are on Google Colab, otherwise skip\n",
        "%%capture\n",
        "!apt purge python3-cairo\n",
        "!apt install libcairo2-dev pkg-config python3-dev\n",
        "!pip install --force-reinstall pycairo\n",
        "!pip install zstandard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c306e849",
      "metadata": {
        "id": "c306e849"
      },
      "source": [
        "### Import other Required Libraries and Seed Random Number Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "623b17ba",
      "metadata": {
        "id": "623b17ba"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import itertools\n",
        "import numpy as np\n",
        "from numpy.random import *\n",
        "import graph_tool.all as gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "p1sePMeSYydS",
      "metadata": {
        "id": "p1sePMeSYydS"
      },
      "outputs": [],
      "source": [
        "global rng\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44db43a3",
      "metadata": {
        "id": "44db43a3"
      },
      "source": [
        "### Define the Neuroidal Model's Empirical Properties\n",
        "The following configuration is for simulating a shared memory representation model with one-step mechanisms, with the intention to adhere to results given in the tables of Valiant (2005). The first six parameters are as described in the referenced paper. The $r_{approx}$ is for generating initial memories in a fixed size to be used in JOIN, and requires prior determination as pursuant to the relations defined in the paper. The most important aspect about choosing a value of $r_{approx}$ is ensuring that JOIN will create new memories of approximately the same size.\n",
        "\n",
        "We also implicitly declare all empirical properties as global variables for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6f2c3634",
      "metadata": {
        "id": "6f2c3634"
      },
      "outputs": [],
      "source": [
        "n = 100000\n",
        "d = 512\n",
        "t = 1\n",
        "k = 32\n",
        "k_adj = 2.0\n",
        "k_m = k * k_adj\n",
        "\n",
        "r_approx = 5420"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duKDVuGfRH9K",
      "metadata": {
        "id": "duKDVuGfRH9K"
      },
      "source": [
        "#### Calculate Edge Existence Probability $p$\n",
        "In the analysis of Valiant (2005) where $n \\ge 10^5$, we have $p = \\frac{d}{n}$.\n",
        "\n",
        "However for lower values of $n$, we find the more general $p = \\frac{d}{n-1}$ to be appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2oh9Zm8mRCZK",
      "metadata": {
        "id": "2oh9Zm8mRCZK"
      },
      "outputs": [],
      "source": [
        "if n >= 10^5:\n",
        "    p = d / n\n",
        "else:\n",
        "    p = d / (n - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qzz-1cFyKGmk",
      "metadata": {
        "id": "qzz-1cFyKGmk"
      },
      "source": [
        "## Generate the Graph Model\n",
        "Here we instantiate a graph model equivalent to the Erdős-Rényi $G=(n,p)$ structure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93048780",
      "metadata": {
        "id": "93048780"
      },
      "source": [
        "### Initialize an Empty Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0f2e3bc2",
      "metadata": {
        "id": "0f2e3bc2"
      },
      "outputs": [],
      "source": [
        "global g\n",
        "g = gt.Graph(directed=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1511c73",
      "metadata": {
        "id": "b1511c73"
      },
      "source": [
        "### Populate our Graph with $n$ Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "525c87ec",
      "metadata": {
        "id": "525c87ec"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "g.add_vertex(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j1nbKsr8YcMP",
      "metadata": {
        "id": "j1nbKsr8YcMP"
      },
      "source": [
        "### Populate our Graph with Random Synapses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "BBySaBFvOPcn",
      "metadata": {
        "id": "BBySaBFvOPcn"
      },
      "outputs": [],
      "source": [
        "def add_gnp_edges(): # Naive implementation\n",
        "    all_edges = itertools.permutations(range(n), 2)\n",
        "    for e in all_edges:\n",
        "        if rng.random() < p:\n",
        "            g.add_edge(*e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PmiwOxuoOXph",
      "metadata": {
        "id": "PmiwOxuoOXph"
      },
      "source": [
        "The following function provides a speed-optimized (yet less readable and more memory intensive) implementation of adding a list of random edges. This version is more reminiscent of the $G=(n,M)$ model, but here we determine the number of edges $M$ using Bernoulli trials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a3ca01e8-82b3-4560-9979-e127f3b2c3fe",
      "metadata": {
        "id": "a3ca01e8-82b3-4560-9979-e127f3b2c3fe"
      },
      "outputs": [],
      "source": [
        "def add_fast_gnp_edges():\n",
        "    num_edges = rng.binomial(n*(n-1)/2, p)\n",
        "    sources = rng.integers(0, n, num_edges*2)\n",
        "    targets = rng.integers(0, n, num_edges*2)\n",
        "    mask = sources != targets # removes self-loops\n",
        "    g.add_edge_list(np.column_stack((sources[mask], targets[mask])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2344Wb3wMUEv",
      "metadata": {
        "id": "2344Wb3wMUEv"
      },
      "outputs": [],
      "source": [
        "#add_gnp_edges() # Space-Efficient\n",
        "add_fast_gnp_edges() # Time-Efficient"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mPQUC3J0VxcA",
      "metadata": {
        "id": "mPQUC3J0VxcA"
      },
      "source": [
        "### Initialize the Mode of all Neurons and Synapses\n",
        "The following two blocks imbue the global properties, or the \"mode\" $s$, of each node and edge in the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fFs3K1sVVF1V",
      "metadata": {
        "id": "fFs3K1sVVF1V"
      },
      "source": [
        "For each neuron $i$, its mode $s_i$ contains the following properties:\n",
        "* $T_i$ specifies the threshold gate value of a given node, commonly set to $1$, or as high as $7$.\n",
        "* $q_i$ stores the state of a given node, initialized as $1$ and set to $2$ if a node is found to be a candidate for memory $C$ during JOIN.\n",
        "  * During *two-step* procedures, this state can also be set to $3$.\n",
        "  * This can be interpreted as the state $q_i$ belonging to a set of finite states $Q = \\{1,2,3\\}$.\n",
        "      * Such states can be representative of how a given neuron is considered \"allocated\" in memory or otherwise.\n",
        "* $f_i$ is a number indicating whether a given neuron is firing ($1$) or not firing ($0$) at the current time step.\n",
        "\n",
        "For efficiency purposes, we omit the storing of the incoming weight sum, $w_{i}$, within in the mode, as it will be calculated in the weight summation functions to be described later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "wgql45kzIyfp",
      "metadata": {
        "id": "wgql45kzIyfp"
      },
      "outputs": [],
      "source": [
        "mode_T = g.new_vp(\"int\")\n",
        "mode_q = g.new_vp(\"int\")\n",
        "mode_f = g.new_vp(\"int\")\n",
        "\n",
        "mode_T.a = t\n",
        "mode_q.a = 1\n",
        "mode_f.a = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ibTJy0O7VKn9",
      "metadata": {
        "id": "ibTJy0O7VKn9"
      },
      "source": [
        "For each synapse $(j,i)$, its mode $s_{ji}$ contains the following:\n",
        "* $w_{ji}$ specifies the weight of the edge from node $j$ to node $i$.\n",
        "  * For *disjoint* representations, this would be initialized to be $\\frac{t}{k}$.\n",
        "  * However, for *shared* representations, we initialize the weight to be $\\frac{t}{k_m}$.\n",
        "* $qq_{ji}$ stores the state of a given edge, set to $1$ and is not updated for one-step procedures.\n",
        "  * For two-step operations, we would have $qq_{ji} \\in Q = \\{1,2\\}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "-jTmXZv9VK1H",
      "metadata": {
        "id": "-jTmXZv9VK1H"
      },
      "outputs": [],
      "source": [
        "mode_w = g.new_ep(\"double\")\n",
        "mode_qq = g.new_ep(\"int\")\n",
        "\n",
        "mode_w.a = t / k_m\n",
        "mode_qq.a = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Vd5E-sO5D4pW",
      "metadata": {
        "id": "Vd5E-sO5D4pW"
      },
      "source": [
        "## Vicinal Algorithms for the JOIN Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6gULnCxHpHCL",
      "metadata": {
        "id": "6gULnCxHpHCL"
      },
      "source": [
        "### Weight Summation Functions\n",
        "The following two blocks both calculate and return\n",
        "$$ w_i = \\sum_{(j,i)\\in E}{} f_{j} \\cdot w_{ji} $$\n",
        "given a neuron $i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ssb1yaRepcRc",
      "metadata": {
        "id": "ssb1yaRepcRc"
      },
      "outputs": [],
      "source": [
        "def sum_weights(s_i): # Naive implementation\n",
        "    w_i = 0\n",
        "    for s_ji in g.iter_in_edges(s_i):\n",
        "        if mode_f[s_ji[0]] == 1:\n",
        "            w_i += mode_w[s_ji]\n",
        "    return w_i"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r-f4bgAbDMxg",
      "metadata": {
        "id": "r-f4bgAbDMxg"
      },
      "source": [
        "This method below is equivalent to the function above, but leverages speed optimizations offered by graph-tool and NumPy to negate the costly, explicit loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "kd7N3vTQxBM4",
      "metadata": {
        "id": "kd7N3vTQxBM4"
      },
      "outputs": [],
      "source": [
        "def fast_sum_weights(s_i):\n",
        "    W = g.get_in_edges(s_i, [mode_w])[:,2]\n",
        "    F = np.array(g.get_in_neighbors(s_i, [mode_f])[:,1], dtype=bool)\n",
        "    return W[F].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q68B5UpbphmD",
      "metadata": {
        "id": "Q68B5UpbphmD"
      },
      "source": [
        "### Neuron and Synapse Mode Updates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8tR6At_o036S",
      "metadata": {
        "id": "8tR6At_o036S"
      },
      "source": [
        "$\\delta\\left(s_{i}, w_{i}\\right) = s_{i}'$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b0b5a251-c46f-4a6f-8249-8f8e11d24cfe",
      "metadata": {
        "id": "b0b5a251-c46f-4a6f-8249-8f8e11d24cfe"
      },
      "outputs": [],
      "source": [
        "def _delta(s_i, w_i):\n",
        "    if w_i > mode_T[s_i]:\n",
        "        mode_f[s_i] = 1\n",
        "        mode_q[s_i] = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0uAB9nfJTig",
      "metadata": {
        "id": "a0uAB9nfJTig"
      },
      "source": [
        "$\\lambda\\left(s_{i}, w_{i}, s_{ji}, f_{j}\\right) = s_{ji}'$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9b2cb273-f13c-4e74-82c1-aae72e328e51",
      "metadata": {
        "id": "9b2cb273-f13c-4e74-82c1-aae72e328e51"
      },
      "outputs": [],
      "source": [
        "def _lambda(s_i, w_i, s_ji, f_j):\n",
        "    if f_j == 1:\n",
        "        mode_qq[s_ji] = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l0TDkN3-pqKl",
      "metadata": {
        "id": "l0TDkN3-pqKl"
      },
      "source": [
        "### Overall Graph Update\n",
        "Note that traversal of each node to calculate the sum of its incoming weights results in one of our most costly procedures in this simulation. We attribute this partly because the Neuroidal model was conceived as a *distributed system* with neurons and synapses acting as their own *agents*. Here they are expressed simply as objects with their attributes being manipulated by our algorithms. Hence, we are performing operations sequentially for each node in the graph, and therefore acknowledge that this overall process is not quite exact to the original formulation of the model.\n",
        "\n",
        "We allow a user to utilize one-step mechanisms using a Boolean function argument. We also allow the skipping of updating the edges of the graph using this argument, as edge updates are not needed in the one-step case. After all updates, we reset the states and firing modes of each neuron/synapse, indicating that the *time step* has been completed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vH41xhO9R_eK",
      "metadata": {
        "id": "vH41xhO9R_eK"
      },
      "source": [
        "#### Shortcut for Determining Memory $C$\n",
        "For convenience, we check for eligible $C$ nodes during the weight sums for each neuron of the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "xS4CchJxL_cw",
      "metadata": {
        "id": "xS4CchJxL_cw"
      },
      "outputs": [],
      "source": [
        "def update_graph(one_step=True):\n",
        "    C = []\n",
        "    for s_i in g.iter_vertices():\n",
        "        w_i = fast_sum_weights(s_i)\n",
        "        _delta(s_i, w_i)\n",
        "        if mode_q[s_i] == 2:\n",
        "            C.append(s_i)\n",
        "            if one_step:\n",
        "                mode_f[s_i] = 0\n",
        "        if not one_step:\n",
        "            for s_ji in g.iter_in_edges(s_i):\n",
        "                f_j = mode_f[s_ji[0]]\n",
        "                _lambda(s_i, w_i, s_ji, f_j)\n",
        "    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b234c00e",
      "metadata": {
        "id": "b234c00e"
      },
      "source": [
        "## The JOIN Algorithm\n",
        "This implements the *one-step* variant of JOIN for *shared* representations as\n",
        "defined in Valiant (2005), explained in further detail here:\n",
        "\n",
        "1. Fire all neurons in given memories $A$ and $B$ \"simultaneously.\"\n",
        "2. Update the graph to determine any threshold transitions.\n",
        "3. Create memory $C$ from neurons that transitioned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cca2362b",
      "metadata": {
        "id": "cca2362b"
      },
      "outputs": [],
      "source": [
        "def JOIN_one_step_shared(A, B):\n",
        "    for i in A + B:\n",
        "        mode_f[i] = 1\n",
        "    C = update_graph(one_step=True)\n",
        "    mode_f.a = 0\n",
        "    mode_q.a = 1\n",
        "    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LgoaK4rk9qsm",
      "metadata": {
        "id": "LgoaK4rk9qsm"
      },
      "source": [
        "## QJOIN: An Optimized JOIN for Centralized Representations\n",
        "The following function makes a couple of additional assumptions about the Neuroidal model and leverages them into a significantly faster algorithm for a centralized implementation:\n",
        "\n",
        "1. Set the weights of all synapses in the model to be $0$.\n",
        "2. Set the weights of the outgoing synapses of $A \\cup B$ to be $\\frac{t}{k_m}$.\n",
        "3. Create memory $C$ from neurons that transitioned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "88edc169-db67-4eec-a3b9-6e315ddefe3f",
      "metadata": {
        "id": "88edc169-db67-4eec-a3b9-6e315ddefe3f"
      },
      "outputs": [],
      "source": [
        "def quick_JOIN(A, B):\n",
        "    mode_w.a = 0\n",
        "    for i in A + B:\n",
        "        mode_w.a[g.get_out_edges(i, [g.edge_index])[:,2]] = t / k_m\n",
        "    return g.get_vertices()[g.get_in_degrees(g.get_vertices(),eweight=mode_w)>t]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IhoxbLGy_IGE",
      "metadata": {
        "id": "IhoxbLGy_IGE"
      },
      "source": [
        "QJOIN does not assume bipartiteness between memories, nor does it require the use of the mode structure aside from storing synapse weights. It does assume that the *synapse weights from the previous time step can be erased*. It also assumes that all neurons have the same threshold value of $t$ at the given time step.\n",
        "\n",
        "It is currently unknown if this version of JOIN remains biologically plausible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "K6-___hLEBca",
      "metadata": {
        "id": "K6-___hLEBca"
      },
      "source": [
        "## Interference Check Function\n",
        "Here we check every memory that is not $A$ or $B$ (referred to as $D$ memories) to calculate how many interfering nodes exist between each given $D$ memory and $C$. If more than $50\\%$ of a $D$ memory is found to interfere with $C$, then an instance of interference has been found. We would then increment the sum of occurrences by $2$, as we consider interference to be bidirectional to both incidental memories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c5zOCQnlkWQN",
      "metadata": {
        "id": "c5zOCQnlkWQN"
      },
      "outputs": [],
      "source": [
        "def interference_check(S, A_i, B_i, C):\n",
        "    sum = 0\n",
        "    for D_i in range(len(S)):\n",
        "        if D_i != A_i and D_i != B_i:\n",
        "            D = S[D_i]\n",
        "            if len(set(C) & set(D)) > (len(D) / 2):\n",
        "                sum += 2\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P9LvyYdlJ9uT",
      "metadata": {
        "id": "P9LvyYdlJ9uT"
      },
      "source": [
        "## Our Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GnmHXRixc4-c",
      "metadata": {
        "id": "GnmHXRixc4-c"
      },
      "source": [
        "### Print Functions for Simulation Updates\n",
        "These three blocks are simply for providing feedback for when: A batch of ongoing JOIN operations completes, the model's capacity is reached, or all memory connectives have been memorized.\n",
        "\n",
        "The interference metric reports are mostly useful for when $n < 10^5$, where the overall system is generally much less stable. Hence, we omit the frequent reporting of it when $n$ is above that value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "KpJ449u2Y2Cq",
      "metadata": {
        "id": "KpJ449u2Y2Cq"
      },
      "outputs": [],
      "source": [
        "def print_join_update(S_length, L, H, H_if, total_if, m_len, m_total):\n",
        "    print(\"Current Total Memories:\", S_length)\n",
        "    print(\"Batch Average Memory Size:\", int(m_len/H))\n",
        "    print(\"Running Average Memory Size:\", int(m_total/(S_length-L)),\"\\n\\n\")\n",
        "    if n < 10^5:\n",
        "        print(\"Batch Interference Rate:\", round(H_if/H, 6))\n",
        "        print(\"Running Average Int. Rate:\", round(total_if/S_length, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "lrzUxnoVZdn0",
      "metadata": {
        "id": "lrzUxnoVZdn0"
      },
      "outputs": [],
      "source": [
        "def print_halt_msg(S_length, L, F, total_if, m_total):\n",
        "    r_obs = int(m_total/(S_length-L))\n",
        "    r_error = round(((r_approx - r_obs) / r_obs) * 100, 2)\n",
        "    print(\"-- End of Simulation (Halted) --\\n\")\n",
        "    print(\"Given: n=\", n, \"d=\", d, \"k=\", k, \"k_adj=\", k_adj, \"\\n r_approx=\",\n",
        "           r_approx, \"START_MEM=\", L)\n",
        "    print(\"we halted Memory Formation at\", F*100, \"% Total Interference.\\n\")\n",
        "    print(\"Empirical Memory Size:\", int(m_total/(S_length-L)))\n",
        "    print(\"Approximation Error of r:\", r_error, \"%\")\n",
        "    print(\"Total Average Interference Rate:\", round(total_if/S_length, 6))\n",
        "    print(\"Capacity:\", L, \"Initial Memories +\" , S_length-L,\"JOIN Memories.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "V0Z1wYcbcVG_",
      "metadata": {
        "id": "V0Z1wYcbcVG_"
      },
      "outputs": [],
      "source": [
        "def print_memorized_msg(S_length, L, F, m_total):\n",
        "    r_obs = int(m_total/(S_length-L))\n",
        "    r_error = round(((r_approx - r_obs) / r_obs) * 100, 2)\n",
        "    print(\"-- End of Simulation (Completed) --\\n\")\n",
        "    print(\"Given: n=\", n, \"d=\", d, \"k=\", k, \"k_adj=\", k_adj, \"\\n r_approx=\",\n",
        "           r_approx, \"START_MEM=\", L, \":\\n\")\n",
        "    print(\"We memorized all combinations of\",L,\"memories\",\"\\n\",\"with less than\",\n",
        "           F*100, \"% interference.\\n\")\n",
        "    print(\"Empirical Memory Size:\", int(m_total/(S_length-L)))\n",
        "    print(\"Approximation Error of r:\", r_error, \"%\")\n",
        "    print(\"Contains:\", L, \"Initial Memories +\" ,S_length-L,\"JOIN Memories.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yXDy093MOJPo",
      "metadata": {
        "id": "yXDy093MOJPo"
      },
      "source": [
        "### Call JOIN until Capacity is reached or all connectives are Memorized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xjEEuq1TGw06",
      "metadata": {
        "id": "xjEEuq1TGw06"
      },
      "source": [
        "#### Simulation Variables\n",
        "* The $L$ parameter specifies how many initial memories to grant the model before calling JOIN.\n",
        "  * Each initial memory will be of fixed size $r_{approx}$ and will consist of random neurons chosen with replacement.\n",
        "* $S$ is our \"memory bank,\" in which we will initially append $L\\choose{2}$ combinations of initial memories, and continue to add memories and check interference as a result of JOIN.\n",
        "* The $F$ parameter determines the level of interference tolerance to be checked at each iteration of JOIN.\n",
        "* (Optional) The $H$ parameter determines how many memories to JOIN in one batch of simulation.\n",
        "  * This is used to observe the model perform at an adjustable level of granularity.\n",
        "* All other variables are primarily used for update reporting.\n",
        "\n",
        "Our simulation will attempt to JOIN all possible $L\\choose{2}$ pairs of initial memories until the model's capacity is reached. If $L\\choose{2}$ is found to be less than our capacity, then the simulation will terminate and have found the model to have memorized all possible connectives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "rhJnNGL3Fqmq",
      "metadata": {
        "id": "rhJnNGL3Fqmq"
      },
      "outputs": [],
      "source": [
        "def JOIN_one_step_shared_simulation(L, F, H=1, fast=True, verbose=True):\n",
        "    m = 0\n",
        "    H_if = 0\n",
        "    m_len = 0\n",
        "    m_total = 0\n",
        "    total_if = 0\n",
        "    print(\"-- Start of Simulation --\\n\")\n",
        "    init_pairs = itertools.combinations(range(L), 2)\n",
        "    S = [rng.choice(np.arange(0,n-1), size=r_approx)\n",
        "         for _ in range(L)]\n",
        "    for A_i,B_i in init_pairs:\n",
        "        A = list(S[A_i])\n",
        "        B = list(S[B_i])\n",
        "        if fast:\n",
        "            C = quick_JOIN(A, B)\n",
        "        else:\n",
        "            C = JOIN_one_step_shared(A, B)\n",
        "        C_if = interference_check(S, A_i, B_i, C)\n",
        "        m += 1\n",
        "        S.append(C)\n",
        "        m_len += len(C)\n",
        "        m_total += len(C)\n",
        "        if m % H == 0:\n",
        "            if verbose:\n",
        "                print_join_update(len(S), L, H, H_if,\n",
        "                                  total_if, m_len, m_total)\n",
        "            H_if = 0\n",
        "            m_len = 0\n",
        "        if C_if > 0:\n",
        "            H_if += C_if\n",
        "            total_if += C_if\n",
        "            if total_if/len(S) > F:\n",
        "              print_halt_msg(len(S), L, F, total_if, m_total)\n",
        "              return S\n",
        "    print_memorized_msg(len(S), L, F, m_total)\n",
        "    return S"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vJHU8uY25TE7",
      "metadata": {
        "id": "vJHU8uY25TE7"
      },
      "source": [
        "### Generate our Memory Bank and Calculate the Empirical Memory Size\n",
        "Given the default parameters, we observe that there is no notable amount of interference (less than $10^{-6}$) for the given amount of memories disjuncted. We are then able to verify the precision in our choice of $r_{approx}$ empirically. We also later observe that the observed capacity of the shared model is clearly greater than the analytical capacity for a disjoint representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "aNeQVo4Ti10v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNeQVo4Ti10v",
        "outputId": "b0b92c65-be76-42f4-b817-0d041bd63ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Start of Simulation --\n",
            "\n",
            "Current Total Memories: 20\n",
            "Batch Average Memory Size: 5459\n",
            "Running Average Memory Size: 5459 \n",
            "\n",
            "\n",
            "Current Total Memories: 30\n",
            "Batch Average Memory Size: 5373\n",
            "Running Average Memory Size: 5416 \n",
            "\n",
            "\n",
            "Current Total Memories: 40\n",
            "Batch Average Memory Size: 5422\n",
            "Running Average Memory Size: 5418 \n",
            "\n",
            "\n",
            "Current Total Memories: 50\n",
            "Batch Average Memory Size: 5392\n",
            "Running Average Memory Size: 5411 \n",
            "\n",
            "\n",
            "-- End of Simulation (Completed) --\n",
            "\n",
            "Given: n= 100000 d= 512 k= 32 k_adj= 2.0 \n",
            " r_approx= 5420 START_MEM= 10 :\n",
            "\n",
            "We memorized all combinations of 10 memories \n",
            " with less than 0.001 % interference.\n",
            "\n",
            "Empirical Memory Size: 5425\n",
            "Approximation Error of r: -0.09 %\n",
            "Contains: 10 Initial Memories + 45 JOIN Memories.\n"
          ]
        }
      ],
      "source": [
        "memory_bank = JOIN_one_step_shared_simulation(L=10,\n",
        "                                              F=.00001,\n",
        "                                              fast=True,\n",
        "                                              H=10, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OzowHbiNEcXC",
      "metadata": {
        "id": "OzowHbiNEcXC"
      },
      "source": [
        "#### Compare Results with the Capacity for the *Disjoint* Representation Model\n",
        "Capacity is measured here by using a result from Table 1 of Valiant (2005)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "SPCPkDu8Ea4r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPCPkDu8Ea4r",
        "outputId": "4927f884-3a8b-4537-afe4-a5ce48e69854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical capacity of disjoint representation: 18\n"
          ]
        }
      ],
      "source": [
        "print(\"Analytical capacity of disjoint representation:\", int(100000 / 5420))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}