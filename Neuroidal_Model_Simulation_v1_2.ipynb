{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0a916e",
   "metadata": {
    "id": "1e0a916e"
   },
   "source": [
    "# Neuroidal Model Simulation v1.2\n",
    "#### Patrick Perrine\n",
    "\n",
    "Code for:\n",
    "\n",
    "Perrine, P. R. (2023). Neural Tabula Rasa: Foundations for Realistic Memories and Learning. Master's thesis. California Polytechnic State University, San Luis Obispo.\n",
    "\n",
    "All algorithms implemented here are originally given by:\n",
    "\n",
    "Valiant, L. G. (2005). Memorization and Association on a Realistic Neural Model. *Neural Computation, 17*, 527–555. https://doi.org/10.1162/0899766053019890\n",
    "\n",
    "Many thanks to Mugizi Rwebangira and Chandradeep Chowdhury for their constant support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MW6UFTD5Yirb",
   "metadata": {
    "id": "MW6UFTD5Yirb"
   },
   "source": [
    "## Introduction\n",
    "We offer the following simulation as an accurate interpretation of the Neuroidal model, as described specifically by Valiant (2005). We place an emphasis on simulating the model to study the behavior of the one-step, shared memory representation for use in unsupervised memorization via the JOIN algorithm. We offer a general implementation framework that should easily extend to the other variants of the model. We choose the Python library *graph-tool* to serve as the basis for storing and performing operations on our random graph model. We opt for this particular library due to its reported performance, code readability, and implementations for visualizing very large, dense graphs (which we leave for future work).\n",
    "\n",
    "We omit an implementation of the LINK procedure, as we do not measure this model based on its ability to recall information. We are primarily concerned with how much information can be stored using JOIN before an intolerable amount of interference occurs between new and pre-existing memories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ca44a",
   "metadata": {
    "id": "3f6ca44a"
   },
   "source": [
    "### Install the *graph-tool* library (https://graph-tool.skewed.de/)\n",
    "The following two code blocks are subject to change based on the library's current hosting location, so referring to the current information from its website may be required. If one needs to run this code without Jupyter: Ignore the following two blocks and please refer to the library's current documentation for proper installation instructions for the desired setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bKylUrLvqy18",
   "metadata": {
    "id": "bKylUrLvqy18"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!echo \"deb http://downloads.skewed.de/apt jammy main\" >> /etc/apt/sources.list\n",
    "!apt-key adv --keyserver keyserver.ubuntu.com --recv-key 612DEFB798507F25\n",
    "!apt-get update\n",
    "!apt-get install python3-graph-tool python3-matplotlib python3-cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "LUmecdYbVIQw",
   "metadata": {
    "id": "LUmecdYbVIQw"
   },
   "outputs": [],
   "source": [
    "# Run this block if you are on Google Colab, otherwise skip\n",
    "%%capture\n",
    "!apt purge python3-cairo\n",
    "!apt install libcairo2-dev pkg-config python3-dev\n",
    "!pip install --force-reinstall pycairo\n",
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306e849",
   "metadata": {
    "id": "c306e849"
   },
   "source": [
    "### Import other Required Libraries and Seed Random Number Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623b17ba",
   "metadata": {
    "id": "623b17ba"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import itertools\n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "p1sePMeSYydS",
   "metadata": {
    "id": "p1sePMeSYydS"
   },
   "outputs": [],
   "source": [
    "global rng\n",
    "rng = np.random.default_rng(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db43a3",
   "metadata": {
    "id": "44db43a3"
   },
   "source": [
    "### Define the Neuroidal Model's Empirical Properties\n",
    "The following configuration for simulating the one-step, shared representation model, with the intention to adhere to results given in Tables 3 and 4 of Valiant (2005). The first five parameters are as described in the referenced paper. The $r_{approx}$ parameter requires prior determination as pursuant to the relations defined in the paper, and is for generating initial memories in a fixed size to be used in JOIN.\n",
    "\n",
    "We also implicitly declare all empirical properties as global variables for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2c3634",
   "metadata": {
    "id": "6f2c3634"
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "d = 512\n",
    "k = 32\n",
    "t = 1\n",
    "k_adj = 1.9\n",
    "\n",
    "r_approx = 5170 # From Table 3 of Valiant (2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duKDVuGfRH9K",
   "metadata": {
    "id": "duKDVuGfRH9K"
   },
   "source": [
    "#### Calculate Edge Existence Probability $p$\n",
    "In the analysis of Valiant (2005) where $n \\ge 10^5$, we have $p = \\frac{d}{n}$.\n",
    "\n",
    "However for lower values of $n$, we find the more general $p = \\frac{d}{n-1}$ to be appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2oh9Zm8mRCZK",
   "metadata": {
    "id": "2oh9Zm8mRCZK"
   },
   "outputs": [],
   "source": [
    "if n >= 10^5:\n",
    "    p = d / n\n",
    "else:\n",
    "    p = d / (n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qzz-1cFyKGmk",
   "metadata": {
    "id": "qzz-1cFyKGmk"
   },
   "source": [
    "## Generate the Graph Model\n",
    "Here we intstantiate a graph model equivalent to the Erdős-Rényi $G=(n,p)$ structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93048780",
   "metadata": {
    "id": "93048780"
   },
   "source": [
    "### Initialize an Empty Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2e3bc2",
   "metadata": {
    "id": "0f2e3bc2"
   },
   "outputs": [],
   "source": [
    "global g\n",
    "g = gt.Graph(directed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1511c73",
   "metadata": {
    "id": "b1511c73"
   },
   "source": [
    "### Populate our Graph with $n$ Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525c87ec",
   "metadata": {
    "id": "525c87ec"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "g.add_vertex(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j1nbKsr8YcMP",
   "metadata": {
    "id": "j1nbKsr8YcMP"
   },
   "source": [
    "### Populate our Graph with Random Synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "BBySaBFvOPcn",
   "metadata": {
    "id": "BBySaBFvOPcn"
   },
   "outputs": [],
   "source": [
    "def add_gnp_edges(): # Naive implementation\n",
    "    all_edges = itertools.permutations(range(n), 2)\n",
    "    for e in all_edges:\n",
    "        if rng.random() < p:\n",
    "            g.add_edge(*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PmiwOxuoOXph",
   "metadata": {
    "id": "PmiwOxuoOXph"
   },
   "source": [
    "The following function provides a speed-optimized (yet less readable and more memory intensive) implementation of adding a list of random edges. This version is more reminiscent of the $G=(n,M)$ model, but we determine the number of edges $M$ using Bernoulli trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ca01e8-82b3-4560-9979-e127f3b2c3fe",
   "metadata": {
    "id": "a3ca01e8-82b3-4560-9979-e127f3b2c3fe"
   },
   "outputs": [],
   "source": [
    "def add_fast_gnp_edges():\n",
    "    num_edges = rng.binomial(n*(n-1)/2, p)\n",
    "    sources = rng.integers(0, n, num_edges*2)\n",
    "    targets = rng.integers(0, n, num_edges*2)\n",
    "    mask = sources != targets # removes self-loops\n",
    "    g.add_edge_list(np.column_stack((sources[mask], targets[mask])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2344Wb3wMUEv",
   "metadata": {
    "id": "2344Wb3wMUEv"
   },
   "outputs": [],
   "source": [
    "#add_gnp_edges() # Space-Efficient\n",
    "add_fast_gnp_edges() # Time-Efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IczuJvx_hfrU",
   "metadata": {
    "id": "IczuJvx_hfrU"
   },
   "source": [
    "We now have a proper $G=(n,p)$ graph to use for our Neuroidal model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mPQUC3J0VxcA",
   "metadata": {
    "id": "mPQUC3J0VxcA"
   },
   "source": [
    "### Initialize the Mode of all Neurons and Synapses\n",
    "The following two blocks imbue the global properties, or the \"mode\" $s$, of each node and edge to the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fFs3K1sVVF1V",
   "metadata": {
    "id": "fFs3K1sVVF1V"
   },
   "source": [
    "For each neuron $i$, its mode $s_i$ contains the following properties:\n",
    "* $T_i$ specifies the threshold gate value of a given node, commonly set to $1$, or as high as $7$.\n",
    "* $q_i$ stores the state of a given node, initialized as $1$ and set to $2$ if a node is found to be a candidate for memory $C$ during JOIN.\n",
    "  * During *two-step* procedures, this state can also be set to $3$.\n",
    "  * This can be interpreted as the state $q_i$ belonging to a set of finite states $Q = \\{1,2,3\\}$.\n",
    "  * Such states can be interpreted as representative of how a given neuron is considered \"allocated\" in memory or otherwise.\n",
    "* $f_i$ is reinterpreted as a Boolean to show whether a give mode is firing (**True**) or not firing (**False**) at the current time step.\n",
    "\n",
    "We omit the storing of the incoming weight sum of a node $w_{i}$ here, as it will be calculated in the weight summation functions as described later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wgql45kzIyfp",
   "metadata": {
    "id": "wgql45kzIyfp"
   },
   "outputs": [],
   "source": [
    "mode_T = g.new_vertex_property(\"int\")\n",
    "mode_q = g.new_vertex_property(\"int\")\n",
    "mode_f = g.new_vertex_property(\"bool\")\n",
    "\n",
    "mode_T.a = t\n",
    "mode_q.a = 1\n",
    "mode_f.a = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ibTJy0O7VKn9",
   "metadata": {
    "id": "ibTJy0O7VKn9"
   },
   "source": [
    "For each synapse $(j,i)$, its mode $s_{ji}$ contains the following:\n",
    "* $w_{ji}$ specifies the weight of the edge from node $j$ to node $i$.\n",
    "  * For *disjoint* representations, this would be initialized to be $\\frac{t}{k}$.\n",
    "  * However, for *shared* representations, we initialize the weight to be $\\frac{t}{k \\cdot {k_{adj}}}$.\n",
    "* $qq_{ji}$ stores the state of a given edge, set to $1$ and is not updated for one-step procedures.\n",
    "  * For two-step operations, we would have $qq_{ji} \\in Q = \\{1,2\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-jTmXZv9VK1H",
   "metadata": {
    "id": "-jTmXZv9VK1H"
   },
   "outputs": [],
   "source": [
    "mode_w = g.new_edge_property(\"double\")\n",
    "mode_qq = g.new_vertex_property(\"int\")\n",
    "\n",
    "mode_w.a = t / (k_adj * k)\n",
    "mode_qq.a = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vd5E-sO5D4pW",
   "metadata": {
    "id": "Vd5E-sO5D4pW"
   },
   "source": [
    "## Vicinal Algorithms for the JOIN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6gULnCxHpHCL",
   "metadata": {
    "id": "6gULnCxHpHCL"
   },
   "source": [
    "### Weight Summation Functions\n",
    "The following two blocks calculate and return\n",
    "$$ w_i = \\sum_{(j,i)\\in E}{} f_{j} \\cdot w_{ji} $$\n",
    "given a neuron $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ssb1yaRepcRc",
   "metadata": {
    "id": "ssb1yaRepcRc"
   },
   "outputs": [],
   "source": [
    "def sum_weights(v_i): # Naive implementation\n",
    "    w_i = 0\n",
    "    for e_ji in g.iter_in_edges(v_i):\n",
    "        if mode_f[e_ji[0]] == True:\n",
    "            w_i += mode_w[e_ji]\n",
    "    return w_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r-f4bgAbDMxg",
   "metadata": {
    "id": "r-f4bgAbDMxg"
   },
   "source": [
    "This method below is equivalent to the function above, but leverages speed optimizations offered by graph-tool and NumPy to negate the costly, explicit loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "kd7N3vTQxBM4",
   "metadata": {
    "id": "kd7N3vTQxBM4"
   },
   "outputs": [],
   "source": [
    "def fast_sum_weights(v_i):\n",
    "    W = g.get_in_edges(v_i, [mode_w])[:,2]\n",
    "    F = np.array(g.get_in_neighbors(v_i, [mode_f])[:,1], dtype=bool)\n",
    "    return W[F].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q68B5UpbphmD",
   "metadata": {
    "id": "Q68B5UpbphmD"
   },
   "source": [
    "### Neuron and Synapse Mode Updates\n",
    "These two blocks, along with the \"mode\" structure in general, are mostly an effort to remain aesthetically similar the original formulations in Valiant (2005) and the earlier work *Circuits of the Mind*. Therefore, these specific functions may be later disregarded in favor of more efficient procedures given our implementation strategy here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8tR6At_o036S",
   "metadata": {
    "id": "8tR6At_o036S"
   },
   "source": [
    "$\\delta\\left(s_{i}, w_{i}\\right) = s_{i}'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0b5a251-c46f-4a6f-8249-8f8e11d24cfe",
   "metadata": {
    "id": "b0b5a251-c46f-4a6f-8249-8f8e11d24cfe"
   },
   "outputs": [],
   "source": [
    "def _delta(v_i, w_i):\n",
    "    if w_i > mode_T[v_i]:\n",
    "        mode_q[v_i] = 2\n",
    "        mode_f[v_i] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0uAB9nfJTig",
   "metadata": {
    "id": "a0uAB9nfJTig"
   },
   "source": [
    "$\\lambda\\left(s_{i}, w_{i}, s_{ji}, f_{j}\\right) = s_{ji}'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2cb273-f13c-4e74-82c1-aae72e328e51",
   "metadata": {
    "id": "9b2cb273-f13c-4e74-82c1-aae72e328e51"
   },
   "outputs": [],
   "source": [
    "def _lambda(v_i, w_i, e_ji, f_j):\n",
    "    if f_j == 1:\n",
    "        mode_qq[e_ji] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l0TDkN3-pqKl",
   "metadata": {
    "id": "l0TDkN3-pqKl"
   },
   "source": [
    "### Overall Graph Update\n",
    "Note that traversal of each node to calculate the sum of its incoming weights results in one of our most costly procedures in this simulation.\n",
    "\n",
    "We attribute this partly because the Neuroidal model was conceived as a *distributed system* with neurons and synapses acting as their own *agents*. Here they are expressed simply as objects with their attributes being manipulated by our algorithms. Hence, we are performing operations sequentially for each node in the graph, and therefore acknowledge that this overall process is not quite exact to the original formulation of the model.\n",
    "\n",
    "After all updates, we reset the states and firing modes of each neuron/synapse, indicating that the *time step* has been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vH41xhO9R_eK",
   "metadata": {
    "id": "vH41xhO9R_eK"
   },
   "source": [
    "#### Shortcut for Determining Memory $C$\n",
    "For convenience, we check for eligible $C$ nodes during the weight sums for each neuron of the graph. We also allow the skipping of updating the edges of the graph for our use of JOIN in the simulation, as edge updates are not needed in our case.\n",
    "\n",
    "Also, we would normally allow a neuron to fire when its threshold is surpassed by its incoming edge weights (known as a threshold transition). However, we reverse such firing here due to it affecting the search for memory $C$ when other nodes will later be checked, and threshold transitions have no other immediate use in our specific simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "xS4CchJxL_cw",
   "metadata": {
    "id": "xS4CchJxL_cw"
   },
   "outputs": [],
   "source": [
    "def update_graph(update_edges=False):\n",
    "    C = []\n",
    "    for v_i in g.iter_vertices():\n",
    "        w_i = fast_sum_weights(v_i)\n",
    "        _delta(v_i, w_i)\n",
    "        if mode_q[v_i] == 2:\n",
    "            C.append(v_i)\n",
    "            mode_f[v_i] = False\n",
    "        if update_edges:\n",
    "            for e_ji in g.iter_in_edges(v_i):\n",
    "                f_j = mode_f[e_ji[0]]\n",
    "                _lambda(v_i, w_i, e_ji, f_j)\n",
    "    mode_q.a = 1\n",
    "    mode_qq.a = 1\n",
    "    mode_f.a = False\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234c00e",
   "metadata": {
    "id": "b234c00e"
   },
   "source": [
    "## The JOIN Algorithm\n",
    "This implements the *one-step* variant of JOIN for *shared* representations as\n",
    "defined in Valiant (2005), explained in further detail here:\n",
    "\n",
    "1. Fire all neurons in given memories $A$ and $B$ \"simultaneously.\"\n",
    "2. Update the graph to determine any threshold transitions.\n",
    "3. Create memory $C$ from neurons that transitioned.\n",
    "\n",
    "We reiterate that all parts of the process are intended to encompass one time step, but this notion is discretized in our formulation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca2362b",
   "metadata": {
    "id": "cca2362b"
   },
   "outputs": [],
   "source": [
    "def JOIN_one_step_shared(A, B):\n",
    "    for v in A + B:\n",
    "        mode_f[v] = True\n",
    "    return update_graph(update_edges=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K6-___hLEBca",
   "metadata": {
    "id": "K6-___hLEBca"
   },
   "source": [
    "## Interference Check Function\n",
    "Here we check every memory that is not $A$ or $B$, referred to as $D$ memories, to calculate how many interfering nodes exist between each given $D$ memory and $C$. If more than $50\\%$ of a $D$ memory is found to interfere with $C$, then an instance of interference has been found. We would then increment the sum of occurrences by $2$, as we consider interference to be bidirectional to both incidental memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5zOCQnlkWQN",
   "metadata": {
    "id": "c5zOCQnlkWQN"
   },
   "outputs": [],
   "source": [
    "def interference_check(S, A_i, B_i, C):\n",
    "    sum = 0\n",
    "    for D_i in range(len(S)):\n",
    "        if D_i != A_i and D_i != B_i:\n",
    "            D = S[D_i]\n",
    "            if len(set(C) & set(D)) > (len(D) / 2):\n",
    "                sum += 2\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P9LvyYdlJ9uT",
   "metadata": {
    "id": "P9LvyYdlJ9uT"
   },
   "source": [
    "## Our Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GnmHXRixc4-c",
   "metadata": {
    "id": "GnmHXRixc4-c"
   },
   "source": [
    "### Print Functions for Simulation Updates\n",
    "These three blocks are simply for providing feedback for whenever: a batch of ongoing JOIN operations completes, the model's capacity is reached, or all memory connectives have been memorized.\n",
    "\n",
    "The interference metric reports are mostly useful for when $n < 10^5$, where the overall system is generally much less stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "KpJ449u2Y2Cq",
   "metadata": {
    "id": "KpJ449u2Y2Cq"
   },
   "outputs": [],
   "source": [
    "def print_join_update(S_length, L, H, H_if, total_if, m_len, m_total):\n",
    "    print(\"Current Total Memories:\", S_length)\n",
    "    print(\"Batch Interference Rate:\", round(H_if/H, 4))\n",
    "    print(\"Batch Average Memory Size:\", int(m_len/H))\n",
    "    print(\"Running Average Interf. Rate:\", round(total_if/S_length, 4))\n",
    "    print(\"Running Average Memory Size:\", int(m_total/(S_length-L)),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "lrzUxnoVZdn0",
   "metadata": {
    "id": "lrzUxnoVZdn0"
   },
   "outputs": [],
   "source": [
    "def print_halt_msg(S_length, L, F, total_if, m_total):\n",
    "    F_p = int(F*100)\n",
    "    r_obs = int(m_total/(S_length-L))\n",
    "    r_error = round(((r_approx - r_obs) / r_obs) * 100, 2)\n",
    "    print(\"-- End of Simulation (Halted) --\\n\")\n",
    "    print(\"Given: n=\", n, \"d=\", d, \"k=\", k, \"k_adj=\", k_adj, \"r_approx=\",\n",
    "           r_approx, \"START_MEM=\", L)\n",
    "    print(\"we halted Memory Formation at\", F_p, \"% Total Interference.\\n\")\n",
    "    print(\"Total Average Interference Rate:\", round(total_if/S_length, 4),\"\\n\")\n",
    "    print(\"Empirical Memory Size:\", int(r_obs))\n",
    "    print(\"Approximation Error of r:\", r_error, \"%\\n\")\n",
    "    print(\"Capacity:\", L, \"Initial Memories +\" ,S_length-L,\"JOIN Memories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "V0Z1wYcbcVG_",
   "metadata": {
    "id": "V0Z1wYcbcVG_"
   },
   "outputs": [],
   "source": [
    "def print_memorized_msg(S_length, L, m_total):\n",
    "    r_obs = int(m_total/(S_length-L))\n",
    "    r_error = round(((r_approx - r_obs) / r_obs) * 100, 2)\n",
    "    print(\"-- End of Simulation (Completed) --\\n\")\n",
    "    print(\"Given: n=\", n, \"d=\", d, \"k=\", k, \"k_adj=\", k_adj, \"r_approx=\",\n",
    "           r_approx, \"START_MEM=\", L)\n",
    "    print(\"we memorized all possible combinations of\", L, \"memories.\\n\")\n",
    "    print(\"Empirical Memory Size:\", int(r_obs))\n",
    "    print(\"Approximation Error of r:\", r_error, \"%\\n\")\n",
    "    print(\"Contains:\", L, \"Initial Memories +\" ,S_length-L,\"JOIN Memories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yXDy093MOJPo",
   "metadata": {
    "id": "yXDy093MOJPo"
   },
   "source": [
    "### Call JOIN until Capacity is reached or all connectives are Memorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xjEEuq1TGw06",
   "metadata": {
    "id": "xjEEuq1TGw06"
   },
   "source": [
    "#### Simulation Parameters\n",
    "* The $L$ parameter specifies how many initial memories to grant the model before calling JOIN.\n",
    "  * Each initial memory will be of fixed size $r_{approx}$ and will consist of randomly chosen neurons with replacement.\n",
    "* $S$ is our \"memory bank\" in which we will initially append $L\\choose{2}$ combinations of initial memories to, and continue to add memories and check interference as a result of JOIN.\n",
    "* The $F$ parameter determines the level of interference tolerance to be checked at each iteration of JOIN.\n",
    "* (Optional) The $H$ parameter determines how many memories to JOIN in one batch of simulation.\n",
    "  * This is mostly used to observe the model perform at an either fine or course-grain level, as determined by the user.\n",
    "* All other variables used are primarily for update reporting.\n",
    "\n",
    "Our simulation will attempt to JOIN all possible $L\\choose{2}$ pairs of initial memories until the model's capacity is reached. If $L\\choose{2}$ is found to be less than our capacity, then the simulation will terminate and have found the model to have memorized all possible connectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rhJnNGL3Fqmq",
   "metadata": {
    "id": "rhJnNGL3Fqmq"
   },
   "outputs": [],
   "source": [
    "def JOIN_one_step_shared_simulation(L, F, H=1, verbose=True):\n",
    "    m = 0\n",
    "    H_if = 0\n",
    "    m_len = 0\n",
    "    m_total = 0\n",
    "    total_if = 0\n",
    "\n",
    "    print(\"-- Start of Simulation --\\n\")\n",
    "\n",
    "    init_pairs = itertools.combinations(range(L), 2)\n",
    "    S = [rng.choice(np.arange(0,n-1), size=r_approx)\n",
    "         for _ in range(L)]\n",
    "\n",
    "    for A_i,B_i in init_pairs:\n",
    "        A = list(S[A_i])\n",
    "        B = list(S[B_i])\n",
    "        C = JOIN_one_step_shared(A, B)\n",
    "        C_if = interference_check(S, A_i, B_i, C)\n",
    "\n",
    "        m += 1\n",
    "        S.append(C)\n",
    "        m_len += len(C)\n",
    "        m_total += len(C)\n",
    "\n",
    "        if m % H == 0:\n",
    "            if verbose:\n",
    "                print_join_update(len(S), L, H, H_if, total_if, m_len, m_total)\n",
    "            H_if = 0\n",
    "            m_len = 0\n",
    "\n",
    "        if C_if > 0:\n",
    "            H_if += C_if\n",
    "            total_if += C_if\n",
    "            if total_if/len(S) > F:\n",
    "              print_halt_msg(len(S), L, F, H, H_if, total_if)\n",
    "              return S\n",
    "\n",
    "    print_memorized_msg(len(S), L, m_total)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vJHU8uY25TE7",
   "metadata": {
    "id": "vJHU8uY25TE7"
   },
   "source": [
    "### Generate our Memory Bank and Calculate the Empirical Memory Size\n",
    "Given the default parameters, we observe that there is no notable amount of interference (less than $0.3\\%$) for the given amount of memories disjuncted. We are then able to verify the precision in our choice of $r_{approx}$ empirically given the performance of the simulation. We also later observe that the observed capacity of the shared model is clearly greater than the analytical capacity for a disjoint representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aNeQVo4Ti10v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNeQVo4Ti10v",
    "outputId": "e2e3de77-3c47-4974-8039-b18d3f92aed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start of Simulation --\n",
      "\n",
      "Current Total Memories: 20\n",
      "Batch Interference Rate: 0.0\n",
      "Batch Average Memory Size: 5204\n",
      "Running Average Interf. Rate: 0.0\n",
      "Running Average Memory Size: 5204 \n",
      "\n",
      "\n",
      "Current Total Memories: 30\n",
      "Batch Interference Rate: 0.0\n",
      "Batch Average Memory Size: 5162\n",
      "Running Average Interf. Rate: 0.0\n",
      "Running Average Memory Size: 5183 \n",
      "\n",
      "\n",
      "Current Total Memories: 40\n",
      "Batch Interference Rate: 0.0\n",
      "Batch Average Memory Size: 5215\n",
      "Running Average Interf. Rate: 0.0\n",
      "Running Average Memory Size: 5194 \n",
      "\n",
      "\n",
      "Current Total Memories: 50\n",
      "Batch Interference Rate: 0.0\n",
      "Batch Average Memory Size: 5185\n",
      "Running Average Interf. Rate: 0.0\n",
      "Running Average Memory Size: 5192 \n",
      "\n",
      "\n",
      "-- End of Simulation (Completed) --\n",
      "\n",
      "Given: n= 100000 d= 512 k= 32 k_adj= 1.9 r_approx= 5170 START_MEM= 10\n",
      "we memorized all possible combinations of 10 memories.\n",
      "\n",
      "Empirical Memory Size: 5188\n",
      "Approximation Error of r: -0.35 %\n",
      "\n",
      "Contains: 10 Initial Memories + 45 JOIN Memories.\n"
     ]
    }
   ],
   "source": [
    "memory_bank = JOIN_one_step_shared_simulation(L=10,\n",
    "                                              F=.003,\n",
    "                                              H=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OzowHbiNEcXC",
   "metadata": {
    "id": "OzowHbiNEcXC"
   },
   "source": [
    "#### Compare Results with the Capacity for the *Disjoint* Representation Model\n",
    "Capacity is measured here by using a result from Table 1 of Valiant (2005) from a model with identical parameters, aside from the $k_{adj}$ value which is not applicable to the disjoint representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "SPCPkDu8Ea4r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPCPkDu8Ea4r",
    "outputId": "5bc48ce1-7c94-4f2f-ae93-bb3e8a1ff82c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical capacity of disjoint representation: 18\n"
     ]
    }
   ],
   "source": [
    "print(\"Analytical capacity of disjoint representation:\", int(100000 / 5420))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
